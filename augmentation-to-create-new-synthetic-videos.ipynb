{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13212845,"sourceType":"datasetVersion","datasetId":8323011}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================\n# Kaggle Video/Data Augmentation (Robust v3 with clear logging)\n# ================================\n# - Fixes \"arrays to stack...\" by extracting audio via ffmpeg -> WAV -> soundfile (no to_soundarray()).\n# - Adds explicit \"Created new video...\" print after each successful file.\n# - Keeps safe fallbacks and attempt caps.\n#\n# Outputs:\n#   /kaggle/working/augmented_videos/*.mp4\n#   /kaggle/working/augmented_labels.csv\n#\n# Assumes dataset structure:\n#   /kaggle/input/interview-videos/videos/*.mp4\n#   /kaggle/input/interview-videos/labels_filenames_only.csv  (cols: video_filename, score)\n\n!pip -q install moviepy==1.0.3 librosa==0.10.1 soundfile==0.12.1 numba==0.58.1 --no-input\n\nimport os, random, tempfile, numpy as np, pandas as pd\nfrom moviepy.editor import VideoFileClip, AudioFileClip, vfx\nimport librosa, soundfile as sf\n\n# ---------- config ----------\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\n\nDATASET_NAME = \"interview-videos\"  # change if your dataset slug differs\nINPUT_DIR   = f\"/kaggle/input/{DATASET_NAME}\"\nVIDEO_DIR   = os.path.join(INPUT_DIR, \"videos\")\nLABELS_CSV  = os.path.join(INPUT_DIR, \"labels_filenames_only.csv\")\n\nOUTPUT_DIR  = \"/kaggle/working/augmented_videos\"\nOUTPUT_CSV  = \"/kaggle/working/augmented_labels.csv\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# New samples to create (per your plan)\nTARGET_NEW = {0: 14, 1: 5, 2: 18}\n\n# ---------- utility ----------\ndef rms(x): return float(np.sqrt(np.mean(np.square(x.astype(np.float64))) + 1e-12))\ndef db_to_ratio(db): return 10.0 ** (db / 20.0)\n\ndef has_audio(clip):\n    try: return clip.audio is not None\n    except Exception: return False\n\ndef safe_basename_noext(path): return os.path.splitext(os.path.basename(path))[0]\n\ndef write_clip(clip, out_path, fps=None):\n    final_fps = fps if fps is not None else (clip.fps if getattr(clip, \"fps\", None) else 25)\n    clip.write_videofile(\n        out_path,\n        codec=\"libx264\",\n        audio_codec=\"aac\",\n        fps=final_fps,\n        threads=2,\n        verbose=False,\n        logger=None,\n        temp_audiofile=os.path.join(tempfile.gettempdir(), \"temp-audio.m4a\"),\n        remove_temp=True,\n    )\n\n# ---------- audio I/O (robust) ----------\ndef extract_audio_array_via_ffmpeg(clip, target_sr=44100):\n    \"\"\"\n    Extract audio by writing to a temp WAV with ffmpeg (MoviePy),\n    then reading with soundfile for consistent shape.\n    Returns (audio_array, sr); audio_array is float32, shape (N,) or (N,2).\n    \"\"\"\n    if not has_audio(clip):\n        raise ValueError(\"no-audio\")\n\n    tmpwav = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\"); tmpwav_path = tmpwav.name; tmpwav.close()\n    # Use moviepy/ffmpeg to resample consistently\n    clip.audio.write_audiofile(tmpwav_path, fps=target_sr, verbose=False, logger=None)\n    y, sr = sf.read(tmpwav_path, dtype=\"float32\", always_2d=True)  # shape (N, C>=1)\n    os.remove(tmpwav_path)\n\n    if y.shape[1] == 1:\n        y = y[:, 0]  # mono -> 1D\n    return y, sr\n\ndef array_to_audioclip(y, sr):\n    \"\"\"Write temp WAV from numpy and return an AudioFileClip which we can attach back to a video.\"\"\"\n    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\"); tmp_path = tmp.name; tmp.close()\n    if y.ndim == 2 and y.shape[1] == 1: y = y[:,0]\n    sf.write(tmp_path, y, sr, subtype=\"PCM_16\")\n    clip = AudioFileClip(tmp_path); clip._temp_wav_path = tmp_path\n    return clip\n\ndef close_temp_audio(clip):\n    try:\n        p = getattr(clip, \"_temp_wav_path\", None)\n        clip.close()\n        if p and os.path.exists(p): os.remove(p)\n    except Exception:\n        pass\n\n# ---------- video-only augments ----------\ndef aug_brightness_contrast(clip, brightness_scale=1.0, contrast=0):\n    contrast = float(np.clip(contrast, -25, 25))\n    out = clip.fx(vfx.colorx, factor=float(np.clip(brightness_scale, 0.9, 1.1)))\n    out = out.fx(vfx.lum_contrast, lum=0, contrast=contrast, contrast_thr=127)\n    return out\n\ndef aug_small_crop(clip, max_border_pct=0.05):\n    w, h = clip.w, clip.h\n    pct = float(random.uniform(0.015, max_border_pct))\n    x1, x2 = int(w*pct), int(w*(1-pct))\n    y1, y2 = int(h*pct), int(h*(1-pct))\n    return clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)\n\ndef aug_micro_speed_jitter(clip, strength=0.02):\n    factor = 1.0 + random.uniform(-strength, strength)\n    return clip.fx(vfx.speedx, factor)\n\ndef aug_speed_change_matched(clip, max_change=0.05):\n    factor = 1.0 + random.uniform(-max_change, max_change)\n    return clip.fx(vfx.speedx, factor)\n\n# ---------- audio numpy transforms ----------\ndef aug_add_light_noise(a, sr, snr_db=25):\n    nrm = rms(a); noise_rms = nrm / db_to_ratio(snr_db)\n    noise = np.random.normal(0, noise_rms, size=a.shape).astype(np.float32)\n    return np.clip(a + noise, -1.0, 1.0)\n\ndef aug_volume_db(a, sr, db_change=-2.0):\n    return np.clip(a * db_to_ratio(db_change), -1.0, 1.0)\n\ndef aug_simple_reverb(a, sr, decay=0.25, delay_ms=40):\n    delay = int(sr * (delay_ms / 1000.0))\n    out = a.copy()\n    if a.ndim == 1:\n        if delay < len(a): out[delay:] = np.clip(out[delay:] + decay * a[:-delay], -1.0, 1.0)\n    else:\n        if delay < len(a): out[delay:, :] = np.clip(out[delay:, :] + decay * a[:-delay, :], -1.0, 1.0)\n    return out\n\ndef aug_pitch_shift_safe(a, sr, semitones=0.5):\n    \"\"\"\n    Robust pitch-shift for mono/stereo:\n    - Channel-wise shift (if stereo)\n    - Trim to shortest channel length\n    \"\"\"\n    if a.ndim == 1:\n        y = librosa.effects.pitch_shift(a.astype(np.float32), sr=sr, n_steps=float(semitones))\n        return np.clip(y, -1.0, 1.0).astype(np.float32)\n    else:\n        chans = []\n        for ch in range(a.shape[1]):\n            y_ch = librosa.effects.pitch_shift(a[:, ch].astype(np.float32), sr=sr, n_steps=float(semitones))\n            chans.append(y_ch)\n        minlen = min(len(c) for c in chans)\n        chans = [c[:minlen].astype(np.float32) for c in chans]\n        y = np.column_stack(tuple(chans))\n        return np.clip(y, -1.0, 1.0).astype(np.float32)\n\ndef apply_audio_numpy_transform(clip, transform_fn, **kwargs):\n    \"\"\"\n    Audio pipeline (robust):\n      VideoFileClip -> ffmpeg write wav -> soundfile read -> numpy transform -> temp wav -> AudioFileClip -> set_audio\n    \"\"\"\n    if not has_audio(clip):\n        raise ValueError(\"no-audio\")\n    y, sr = extract_audio_array_via_ffmpeg(clip, target_sr=44100)\n    y2 = transform_fn(y, sr, **kwargs)\n    audio_new = array_to_audioclip(y2, sr)\n    new_clip = clip.set_audio(audio_new)\n    return new_clip, audio_new\n\n# ---------- per-class strategies (return tag too) ----------\ndef choose_aug_for_class0(clip):\n    audio_ok = has_audio(clip)\n    options = [\"vid_bc\", \"vid_crop\", \"vid_jitter\", \"av_speed\"]\n    if audio_ok: options += [\"aud_noise\", \"aud_pitch\"]\n    choice = random.choice(options)\n    temp_audio = None\n    if choice == \"vid_bc\":\n        aug = aug_brightness_contrast(clip, 1.0 + random.uniform(-0.08, 0.08), random.uniform(-15, 15))\n        tag = \"bc\"\n    elif choice == \"vid_crop\":\n        aug = aug_small_crop(clip, 0.05); tag = \"crop\"\n    elif choice == \"vid_jitter\":\n        aug = aug_micro_speed_jitter(clip, 0.02); tag = \"micro_speed\"\n    elif choice == \"av_speed\":\n        aug = aug_speed_change_matched(clip, 0.05); tag = \"speed\"\n    elif choice == \"aud_noise\":\n        aug, temp_audio = apply_audio_numpy_transform(clip, aug_add_light_noise, snr_db=random.uniform(22, 30))\n        tag = \"noise\"\n    elif choice == \"aud_pitch\":\n        semis = random.choice([-1.0, -0.5, 0.5, 1.0])\n        aug, temp_audio = apply_audio_numpy_transform(clip, aug_pitch_shift_safe, semitones=semis)\n        tag = f\"pitch({semis:+.1f})\"\n    else:\n        aug, tag = clip, \"none\"\n    return aug, temp_audio, tag\n\ndef choose_aug_for_class1(clip):\n    choice = random.choice([\"vid_bc\", \"vid_crop\"])\n    temp_audio = None\n    if choice == \"vid_bc\":\n        aug = aug_brightness_contrast(clip, 1.0 + random.uniform(-0.06, 0.06), random.uniform(-10, 10))\n        tag = \"bc\"\n    else:\n        aug = aug_small_crop(clip, 0.04); tag = \"crop\"\n    return aug, temp_audio, tag\n\ndef choose_aug_for_class2(clip):\n    audio_ok = has_audio(clip)\n    include_speed = random.random() < 0.5\n    aug = aug_brightness_contrast(clip, 1.0 + random.uniform(-0.1, 0.1), random.uniform(-18, 18))\n    tag_parts = [\"bc\"]\n    if include_speed:\n        aug = aug_speed_change_matched(aug, 0.05)\n        tag_parts.append(\"speed\")\n\n    temp_audio = None\n    if audio_ok:\n        which_audio = random.choice([\"noise\", \"pitch\", \"vol\", \"reverb\"])\n        if which_audio == \"noise\":\n            aug, temp_audio = apply_audio_numpy_transform(aug, aug_add_light_noise, snr_db=random.uniform(22, 30))\n            tag_parts.append(\"noise\")\n        elif which_audio == \"pitch\":\n            semis = random.choice([-1.0, -0.5, 0.5, 1.0])\n            aug, temp_audio = apply_audio_numpy_transform(aug, aug_pitch_shift_safe, semitones=semis)\n            tag_parts.append(f\"pitch{semis:+.1f}\")\n        elif which_audio == \"vol\":\n            db = random.uniform(-3.0, 2.0)\n            aug, temp_audio = apply_audio_numpy_transform(aug, aug_volume_db, db_change=db)\n            tag_parts.append(f\"vol{db:+.1f}dB\")\n        else:\n            aug, temp_audio = apply_audio_numpy_transform(aug, aug_simple_reverb,\n                                                         decay=random.uniform(0.15,0.3),\n                                                         delay_ms=random.uniform(25,55))\n            tag_parts.append(\"reverb\")\n    tag = \"_\".join(tag_parts)\n    return aug, temp_audio, tag\n\n# ---------- data ----------\ndf = pd.read_csv(LABELS_CSV)\nassert set(df.columns) >= {\"video_filename\", \"score\"}, \"CSV must have columns: video_filename, score\"\n\nclass_to_files = {0: [], 1: [], 2: []}\nfor _, row in df.iterrows():\n    fn, lab = str(row[\"video_filename\"]).strip(), int(row[\"score\"])\n    full = os.path.join(VIDEO_DIR, fn)\n    if os.path.exists(full) and lab in class_to_files:\n        class_to_files[lab].append(full)\n\nprint(\"Found per-class originals:\")\nfor k, v in class_to_files.items():\n    print(f\"  Class {k}: {len(v)} files\")\n\n# ---------- main ----------\nrows_for_csv = []\n\ndef safe_video_only_fallback(clip):\n    if random.random() < 0.5:\n        return aug_brightness_contrast(clip, 1.0 + random.uniform(-0.06, 0.06), random.uniform(-10, 10)), \"fallback_bc\"\n    else:\n        return aug_small_crop(clip, 0.04), \"fallback_crop\"\n\ndef generate_for_class(label, n_new, choose_aug_fn, cycle_all=False):\n    originals = class_to_files[label]\n    assert len(originals) > 0, f\"No originals for class {label}\"\n\n    created, attempts = 0, 0\n    max_attempts = max(60, n_new * 20)\n\n    while created < n_new and attempts < max_attempts:\n        src_path = originals[attempts % len(originals)] if cycle_all else random.choice(originals)\n        attempts += 1\n        base = safe_basename_noext(src_path)\n\n        try:\n            with VideoFileClip(src_path) as clip:\n                aug_clip, temp_aud, tag = choose_aug_fn(clip)\n                out_name = f\"{base}_aug{created+1:02d}_{tag}.mp4\"\n                out_path = os.path.join(OUTPUT_DIR, out_name)\n                write_clip(aug_clip, out_path, fps=getattr(clip, \"fps\", None))\n                rows_for_csv.append((out_name, label))\n                if temp_aud is not None: close_temp_audio(temp_aud)\n                aug_clip.close()\n                created += 1\n                print(f\"Created new video using technique '{tag}' → {out_name}\")\n                continue\n\n        except Exception as e:\n            print(f\"[WARN] Primary augment failed on {src_path}: {e}. Trying safe video-only fallback...\")\n            try:\n                with VideoFileClip(src_path) as clip2:\n                    safe_clip, tag = safe_video_only_fallback(clip2)\n                    out_name = f\"{base}_aug{created+1:02d}_{tag}.mp4\"\n                    out_path = os.path.join(OUTPUT_DIR, out_name)\n                    write_clip(safe_clip, out_path, fps=getattr(clip2, \"fps\", None))\n                    rows_for_csv.append((out_name, label))\n                    safe_clip.close()\n                    created += 1\n                    print(f\"Created new video using technique '{tag}' → {out_name}\")\n                    continue\n            except Exception as e2:\n                print(f\"[WARN] Fallback also failed on {src_path}: {e2}. Moving on...\")\n\n    if created < n_new:\n        print(f\"[NOTE] Class {label}: created {created}/{n_new} (attempts={attempts}, cap={max_attempts}).\")\n\n# Class 0: +14\ngenerate_for_class(0, TARGET_NEW[0], choose_aug_fn=choose_aug_for_class0, cycle_all=False)\n# Class 1: +5\ngenerate_for_class(1, TARGET_NEW[1], choose_aug_fn=choose_aug_for_class1, cycle_all=False)\n# Class 2: +18 (cycle through all originals)\ngenerate_for_class(2, TARGET_NEW[2], choose_aug_fn=choose_aug_for_class2, cycle_all=True)\n\n# ---------- write CSV for new items ----------\npd.DataFrame(rows_for_csv, columns=[\"video_filename\", \"score\"]).to_csv(OUTPUT_CSV, index=False)\nprint(f\"\\nCreated {len(rows_for_csv)} augmented videos in: {OUTPUT_DIR}\")\nprint(f\"Wrote CSV: {OUTPUT_CSV}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T02:40:38.598834Z","iopub.execute_input":"2025-10-03T02:40:38.599059Z","iopub.status.idle":"2025-10-03T03:28:27.551078Z","shell.execute_reply.started":"2025-10-03T02:40:38.599033Z","shell.execute_reply":"2025-10-03T03:28:27.550306Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnumba-cuda 0.2.0 requires numba>=0.59.1, but you have numba 0.58.1 which is incompatible.\ndask-cuda 25.2.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\ncuml-cu12 25.2.1 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\ncudf-cu12 25.2.2 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\ndistributed-ucxx-cu12 0.42.0 requires numba<0.61.0a0,>=0.59.1, but you have numba 0.58.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"error: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","output_type":"stream"},{"name":"stdout","text":"Found per-class originals:\n  Class 0: 11 files\n  Class 1: 24 files\n  Class 2: 7 files\nCreated new video using technique 'bc' → raj8_aug01_bc.mp4\nCreated new video using technique 'crop' → jani6_aug02_crop.mp4\nCreated new video using technique 'pitch(-1.0)' → raj8_aug03_pitch(-1.0).mp4\nCreated new video using technique 'speed' → raj5_aug04_speed.mp4\nCreated new video using technique 'crop' → jani4_aug05_crop.mp4\nCreated new video using technique 'bc' → raj5_aug06_bc.mp4\nCreated new video using technique 'speed' → raj4_aug07_speed.mp4\nCreated new video using technique 'micro_speed' → raj5_aug08_micro_speed.mp4\nCreated new video using technique 'crop' → jani3_aug09_crop.mp4\nCreated new video using technique 'micro_speed' → jani9_aug10_micro_speed.mp4\nCreated new video using technique 'bc' → jani9_aug11_bc.mp4\nCreated new video using technique 'noise' → jani9_aug12_noise.mp4\nCreated new video using technique 'pitch(+1.0)' → jani3_aug13_pitch(+1.0).mp4\nCreated new video using technique 'bc' → raj4_aug14_bc.mp4\nCreated new video using technique 'crop' → raj6_aug01_crop.mp4\nCreated new video using technique 'crop' → raj9_aug02_crop.mp4\nCreated new video using technique 'bc' → rx4_aug03_bc.mp4\nCreated new video using technique 'bc' → lj2_aug04_bc.mp4\nCreated new video using technique 'crop' → lj5_aug05_crop.mp4\nCreated new video using technique 'bc_vol+0.5dB' → anjaly_1_aug01_bc_vol+0.5dB.mp4\nCreated new video using technique 'bc_pitch-0.5' → anjaly_3_aug02_bc_pitch-0.5.mp4\nCreated new video using technique 'bc_speed_pitch+0.5' → blu1_aug03_bc_speed_pitch+0.5.mp4\nCreated new video using technique 'bc_noise' → lj1_aug04_bc_noise.mp4\nCreated new video using technique 'bc_speed_vol-1.9dB' → lj7_aug05_bc_speed_vol-1.9dB.mp4\nCreated new video using technique 'bc_speed_pitch-0.5' → lj8_aug06_bc_speed_pitch-0.5.mp4\nCreated new video using technique 'bc_reverb' → rx1_aug07_bc_reverb.mp4\nCreated new video using technique 'bc_speed_noise' → anjaly_1_aug08_bc_speed_noise.mp4\nCreated new video using technique 'bc_speed_reverb' → anjaly_3_aug09_bc_speed_reverb.mp4\nCreated new video using technique 'bc_noise' → blu1_aug10_bc_noise.mp4\nCreated new video using technique 'bc_speed_vol-2.4dB' → lj1_aug11_bc_speed_vol-2.4dB.mp4\nCreated new video using technique 'bc_speed_vol+1.9dB' → lj7_aug12_bc_speed_vol+1.9dB.mp4\nCreated new video using technique 'bc_vol+1.2dB' → lj8_aug13_bc_vol+1.2dB.mp4\nCreated new video using technique 'bc_pitch-1.0' → rx1_aug14_bc_pitch-1.0.mp4\nCreated new video using technique 'bc_vol+1.4dB' → anjaly_1_aug15_bc_vol+1.4dB.mp4\nCreated new video using technique 'bc_noise' → anjaly_3_aug16_bc_noise.mp4\nCreated new video using technique 'bc_speed_pitch+1.0' → blu1_aug17_bc_speed_pitch+1.0.mp4\nCreated new video using technique 'bc_reverb' → lj1_aug18_bc_reverb.mp4\n\nCreated 37 augmented videos in: /kaggle/working/augmented_videos\nWrote CSV: /kaggle/working/augmented_labels.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Zip up the augmented videos + CSV and provide a download link (Kaggle)\nimport os\nfrom zipfile import ZipFile, ZIP_DEFLATED\nfrom IPython.display import FileLink, display\n\n# If you used my earlier cells, these paths already exist:\nOUTPUT_DIR = \"/kaggle/working/augmented_videos\"\nOUTPUT_CSV = \"/kaggle/working/augmented_labels.csv\"\n\nZIP_PATH = \"/kaggle/working/augmented_package.zip\"\n\n# Sanity checks\nassert os.path.isdir(OUTPUT_DIR), f\"Missing folder: {OUTPUT_DIR}\"\nassert os.path.isfile(OUTPUT_CSV), f\"Missing CSV: {OUTPUT_CSV}\"\n\n# Create zip (overwrite if it exists)\nfile_count = 0\nwith ZipFile(ZIP_PATH, mode=\"w\", compression=ZIP_DEFLATED) as zf:\n    # Add all videos, keeping them inside 'augmented_videos/' folder in the zip\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for fn in files:\n            src_path = os.path.join(root, fn)\n            # Build archive name to preserve folder name\n            arcname = os.path.join(\"augmented_videos\", os.path.relpath(src_path, OUTPUT_DIR))\n            zf.write(src_path, arcname)\n            file_count += 1\n    # Add the CSV at the top level\n    zf.write(OUTPUT_CSV, arcname=\"augmented_labels.csv\")\n    file_count += 1\n\nsize_mb = os.path.getsize(ZIP_PATH) / (1024 * 1024)\nprint(f\"Zipped {file_count} files into: {ZIP_PATH}  ({size_mb:.2f} MB)\")\n\n# Show a clickable link (you can also grab it from the right 'Output' panel)\ndisplay(FileLink(ZIP_PATH, result_html_prefix=\"Click to download → \"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T03:32:12.316198Z","iopub.execute_input":"2025-10-03T03:32:12.316812Z","iopub.status.idle":"2025-10-03T03:32:20.202394Z","shell.execute_reply.started":"2025-10-03T03:32:12.316779Z","shell.execute_reply":"2025-10-03T03:32:20.201665Z"}},"outputs":[{"name":"stdout","text":"Zipped 38 files into: /kaggle/working/augmented_package.zip  (204.90 MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/augmented_package.zip","text/html":"Click to download → <a href='/kaggle/working/augmented_package.zip' target='_blank'>/kaggle/working/augmented_package.zip</a><br>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}